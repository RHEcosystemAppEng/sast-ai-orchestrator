# Implemented MLOps Database Schemas for SAST-AI-Workflow

## Implementation Status: ✅ COMPLETED

This document reflects the **actual implemented schema** in the SAST-AI-Orchestrator application, with the corrected naming convention applied.

## Naming Convention

- **Primary Keys**: Always named `id` in their own tables  
- **Foreign Keys**: Named descriptively when referencing other tables:
  - `job_id` when referencing the `job` table
  - `job_batch_id` when referencing the `job_batch` table
  - `job_batch_run_definition_id` when referencing pipeline definitions
- **Shared Primary Keys**: Use `id` and reference parent's `id` via JPA `@MapsId`

---

## Part 1: Job Orchestration & Pipeline Tracking Schemas

### 1. Job Batch (Orchestrator Runs)
**Maps to ADR: `orchestrator_runs` and `pipeline_runs`**

**JPA Entity**: `JobBatch.java`
```sql
CREATE TABLE job_batch (
    id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
    batch_google_sheet_url VARCHAR(255) NOT NULL,
    submitted_by VARCHAR(255),
    submitted_at TIMESTAMP(6) WITHOUT TIME ZONE NOT NULL,
    status VARCHAR(255) NOT NULL CHECK (status IN ('PROCESSING', 'COMPLETED', 'COMPLETED_WITH_ERRORS', 'COMPLETED_EMPTY', 'FAILED', 'CANCELLED')),
    total_jobs INTEGER,
    completed_jobs INTEGER,
    failed_jobs INTEGER,
    last_updated_at TIMESTAMP(6) WITHOUT TIME ZONE,
    use_known_false_positive_file BOOLEAN,
    job_batch_run_definition_id BIGINT,
    FOREIGN KEY (job_batch_run_definition_id) REFERENCES job_batch_run_definitions(id)
);
```

### 2. Job (Individual Pipeline Runs)
**Maps to ADR: `pipeline_runs`**

**JPA Entity**: `Job.java`
```sql
CREATE TABLE job (
    id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
    job_batch_id BIGINT,
    project_name VARCHAR(255),
    project_version VARCHAR(255),
    package_name VARCHAR(255),
    package_nvr VARCHAR(255),
    osh_scan_id VARCHAR(255),
    package_source_code_url VARCHAR(255),
    jira_link VARCHAR(255),
    hostname VARCHAR(255),
    known_false_positives_url VARCHAR(255),
    input_source_type VARCHAR(255) CHECK (input_source_type IN ('SARIF', 'GOOGLE_SHEET')),
    google_sheet_url VARCHAR(255),
    status VARCHAR(255) NOT NULL CHECK (status IN ('PENDING', 'SCHEDULED', 'RUNNING', 'COMPLETED', 'FAILED', 'CANCELLED')),
    created_at TIMESTAMP(6) WITHOUT TIME ZONE NOT NULL,
    started_at TIMESTAMP(6) WITHOUT TIME ZONE,
    completed_at TIMESTAMP(6) WITHOUT TIME ZONE,
    cancelled_at TIMESTAMP(6) WITHOUT TIME ZONE,
    tekton_url VARCHAR(255),
    last_updated_at TIMESTAMP(6) WITHOUT TIME ZONE,
    submitted_by VARCHAR(255),
    FOREIGN KEY (job_batch_id) REFERENCES job_batch(id)
);
```

### 3. Job Batch Execution Context
**Maps to ADR: `execution_context`**

**JPA Entity**: `JobBatchExecutionContext.java`
```sql
CREATE TABLE job_batch_execution_context (
    id BIGINT PRIMARY KEY,  -- Shared PK with job_batch
    environment VARCHAR(100) NOT NULL,
    config_version VARCHAR(50) NOT NULL,
    hw_spec JSONB NOT NULL,
    FOREIGN KEY (id) REFERENCES job_batch(id)
);

CREATE INDEX idx_job_batch_execution_context_environment ON job_batch_execution_context(environment);
CREATE INDEX idx_job_batch_execution_context_config_version ON job_batch_execution_context(config_version);
```

### 4. Job Batch Run Definition (Pipeline Definitions)
**Maps to ADR: `pipeline_definitions`**

**JPA Entity**: `JobBatchRunDefinition.java`
```sql
CREATE TABLE job_batch_run_definitions (
    id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
    pipeline_definition_id VARCHAR(255) UNIQUE NOT NULL,
    name VARCHAR(255) NOT NULL,
    version VARCHAR(50) NOT NULL,
    git_hash VARCHAR(40) NOT NULL,
    description TEXT,
    workflow_graph_topology_id BIGINT,
    metadata JSONB NOT NULL,
    created_at TIMESTAMP(6) WITHOUT TIME ZONE NOT NULL,
    FOREIGN KEY (workflow_graph_topology_id) REFERENCES workflow_graph_topology(id)
);
```

### 5. Workflow Graph Topology (Pipeline Topology)
**Maps to ADR: `pipeline_topology`**

**JPA Entity**: `WorkflowGraphTopology.java`
```sql
CREATE TABLE workflow_graph_topology (
    id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
    topology_id INTEGER UNIQUE NOT NULL,
    description TEXT,
    edges JSONB NOT NULL
);
```

---

## Part 2: Token Management & Cost Tracking Schemas

### 6. Job Token Usage
**Maps to ADR: `token_usage`**

**JPA Entity**: `JobTokenUsage.java`
```sql
CREATE TABLE job_token_usage (
    id BIGINT PRIMARY KEY,  -- Shared PK with job
    total_input_tokens INTEGER NOT NULL,
    total_output_tokens INTEGER NOT NULL,
    total_tokens INTEGER NOT NULL,
    node_breakdown JSONB NOT NULL,
    estimated_cost DECIMAL(10,4) NOT NULL,
    created_at TIMESTAMP(6) WITHOUT TIME ZONE NOT NULL,
    FOREIGN KEY (id) REFERENCES job(id)
);
```

### 7. Pricing Models
**Maps to ADR: `pricing_models`**

**JPA Entity**: `PricingModels.java`
```sql
CREATE TABLE pricing_models (
    pricing_model_id VARCHAR(100) PRIMARY KEY,
    model_name VARCHAR(100) NOT NULL,
    provider VARCHAR(50) NOT NULL,
    input_price_per_1k DECIMAL(8,6) NOT NULL,
    output_price_per_1k DECIMAL(8,6) NOT NULL,
    currency VARCHAR(3) NOT NULL DEFAULT 'USD',
    effective_from TIMESTAMP(6) WITHOUT TIME ZONE NOT NULL,
    effective_to TIMESTAMP(6) WITHOUT TIME ZONE
);
```

---

## Part 3: Data Versioning & Lineage Schemas

### 8. Data Artifacts
**Maps to ADR: `data_artifacts`**

**JPA Entity**: `DataArtifacts.java`
```sql
CREATE TABLE data_artifacts (
    artifact_id VARCHAR(255) PRIMARY KEY,
    artifact_type VARCHAR(100) NOT NULL,
    name VARCHAR(255) NOT NULL,
    version VARCHAR(100) NOT NULL,
    dvc_path VARCHAR(500) NOT NULL,
    dvc_hash VARCHAR(255) NOT NULL,
    metadata JSONB NOT NULL,
    created_at TIMESTAMP(6) WITHOUT TIME ZONE NOT NULL
);
```

### 9. Job Batch Data Lineage
**Maps to ADR: `data_lineage`**

**JPA Entity**: `JobBatchDataLineage.java`
```sql
CREATE TABLE job_batch_data_lineage (
    id BIGINT PRIMARY KEY,  -- Shared PK with job_batch
    lineage_id VARCHAR(255) NOT NULL,
    input_artifacts JSONB NOT NULL,
    transformation_type VARCHAR(100) NOT NULL,
    created_at TIMESTAMP(6) WITHOUT TIME ZONE NOT NULL,
    FOREIGN KEY (id) REFERENCES job_batch(id)
);
```

---

## Part 4: Monitoring & Observability Schemas

### 10. Job Metrics
**Maps to ADR: `pipeline_metrics`**

**JPA Entity**: `JobMetrics.java`
```sql
CREATE TABLE job_metrics (
    id BIGINT PRIMARY KEY,  -- Shared PK with job
    package_name VARCHAR(255) NOT NULL,
    total_issues INTEGER NOT NULL,
    predicted_issues_count INTEGER NOT NULL,
    predicted_non_issues_count INTEGER NOT NULL,
    actual_issues_count INTEGER,
    actual_non_issues_count INTEGER,
    has_ground_truth BOOLEAN NOT NULL DEFAULT FALSE,
    precision DECIMAL(5,4),
    recall DECIMAL(5,4),
    f1_score DECIMAL(5,4),
    accuracy DECIMAL(5,4),
    confusion_matrix JSONB,
    node_metrics JSONB,
    created_at TIMESTAMP(6) WITHOUT TIME ZONE NOT NULL,
    FOREIGN KEY (id) REFERENCES job(id)
);
```

### 11. Job Settings (Extended Job Configuration)
**JPA Entity**: `JobSettings.java`
```sql
CREATE TABLE job_settings (
    id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
    job_id BIGINT,
    secret_name VARCHAR(255),
    FOREIGN KEY (job_id) REFERENCES job(id)
);
```

---

## Implementation Notes

### Relationship Summary
1. **JobBatch (1) → Jobs (Many)**: `job.job_batch_id → job_batch.id`
2. **JobBatch (1) ↔ JobBatchExecutionContext (1)**: Shared primary key via `@MapsId`
3. **JobBatch (1) ↔ JobBatchDataLineage (1)**: Shared primary key via `@MapsId`
4. **Job (1) ↔ JobTokenUsage (1)**: Shared primary key via `@MapsId`
5. **Job (1) ↔ JobMetrics (1)**: Shared primary key via `@MapsId`
6. **Job (1) ↔ JobSettings (1)**: `job_settings.job_id → job.id`

### Key Design Decisions
- **Removed execution_context_id from Job**: Jobs access execution context via `job_batch_id`
- **Shared Primary Keys**: Used for 1:1 relationships to avoid foreign key columns
- **Descriptive Foreign Keys**: All foreign keys clearly indicate which table they reference
- **JSONB Support**: Used for flexible metadata storage (hw_spec, node_breakdown, etc.)

### Application Status
- ✅ All JPA entities implemented
- ✅ Database schema created and tested
- ✅ Application compiles and runs successfully
- ✅ Relationships verified with test data
- ✅ Naming convention consistently applied